ğŸ“˜ Local Document Summarizer + Q&A System

A local Retrieval-Augmented Generation (RAG) system built in Python 3.11, using:

ğŸ§  Ollama (Phi-3 or Mistral models) for local LLM inference

ğŸ” ChromaDB for document vector storage

ğŸ’¬ Sentence Transformers (all-mpnet-base-v2) for text embeddings

ğŸ“„ PyPDF2 for PDF document parsing

This project allows users to:

Upload documents (.pdf, .txt, .md)

Ask questions based only on the document content

Get summaries of documents

Run fully offline â€” no external API calls

ğŸš€ Features

âœ… Add local documents to the vector store
âœ… Ask context-based questions from those documents
âœ… Generate accurate summaries using Phi3
âœ… Persist data locally with ChromaDB
âœ… Fully private & offline â€“ works entirely on your machine



ğŸ§© Tech Stack


| Component           | Library / Tool                                        |
| ------------------- | ----------------------------------------------------- |
| **LLM Engine**      | [Ollama](https://ollama.ai) (`phi3`, `mistral`, etc.) |
| **Embeddings**      | `sentence-transformers (all-mpnet-base-v2)`           |
| **Vector Database** | `chromadb`                                            |
| **PDF Reader**      | `PyPDF2`                                              |
| **Language**        | Python 3.11                                           |


âš™ï¸ Installation

1ï¸âƒ£ Clone the Repository
git clone https://github.com/<your-username>/<your-repo-name>.git
cd <your-repo-name>


2ï¸âƒ£ Create and Activate Virtual Environment

python -m venv venv
# On Windows:
venv\Scripts\activate
# On Mac/Linux:
source venv/bin/activate


3ï¸âƒ£ Install Requirements

pip install -r requirements.txt

4ï¸âƒ£ Install and Run Ollama

Download Ollama from https://ollama.ai
 and start the Ollama service:

ollama run phi3

ğŸ“„ Example Usage
Start the App
python main.py


Youâ€™ll see an interactive prompt:

============================================================
Local Document Q&A System (Ollama + Phi3)
============================================================

Commands:
  add <filepath>       - Add a document
  ask <question>       - Ask a question
  summarize <filepath> - Summarize a document
  clear                - Clear database
  quit                 - Exit



  Example Session
> add Resume.pdf
ğŸ“„ Processing: Resume.pdf
âœ“ Added 12 chunks to vector store

> ask What skills does this person have?
ğŸ’¡ Answer: The person has skills in Python, machine learning, and data analysis.

> summarize Resume.pdf
ğŸ“‹ Summary:
This resume summarizes a software developer specializing in AI and ML.

ğŸ“¦ Folder Structure
RAG/
â”‚
â”œâ”€â”€ venv/                   # Virtual environment
â”œâ”€â”€ main.py                 # Core RAG code
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ Resume.pdf              # Example document
â””â”€â”€ .gitignore              # Ignore unnecessary files

ğŸ§  Key Functions
Function	Description
add_document(file_path)	Adds a document to ChromaDB
answer_question(question)	Answers based on context from documents
summarize_document(file_path)	Summarizes a full document
clear_database()	Clears the local vector store
ğŸ§° Requirements File

Example requirements.txt:

chromadb
sentence-transformers
PyPDF2
ollama

ğŸ§‘â€ğŸ’» Developer Notes

Default Ollama model: phi3

ChromaDB persistence folder: ./chroma_db

Supports .pdf, .txt, .md, .rst

Recommended embedding model: all-mpnet-base-v2

ğŸ›¡ï¸ License

MIT License Â© 2025